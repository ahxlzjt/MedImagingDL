{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ahxlzjt/MedImagingDL/blob/CH01_Deep-Learning-Basic/MLP_in_PyTorch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rt63f8XbTrgb"
      },
      "outputs": [],
      "source": [
        "from sklearn import datasets\n",
        "dataset = datasets.load_iris()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "X = torch.tensor(dataset.data, dtype=torch.float32)\n",
        "y = torch.tensor(dataset.target)"
      ],
      "metadata": {
        "id": "3o__mb9CUZoU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self, hidden_units):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(4, hidden_units)\n",
        "    self.fc2 = nn.Linear(hidden_units, 3)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = self.fc2(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "lsatWxd6T7vH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(5)"
      ],
      "metadata": {
        "id": "78oXC-F5LiqG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "criterion = nn.CrossEntropyLoss()"
      ],
      "metadata": {
        "id": "TOZmBIh3UnT6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, optimizer, criterion):\n",
        "  for epoch in range(100):\n",
        "    y_pred = model(X)\n",
        "\n",
        "    loss = criterion(y_pred, y)\n",
        "    print(f\"Epoch: {epoch} / Loss: {loss}\")\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "train(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTngoWE1Vsxi",
        "outputId": "7062447e-99fa-412e-a825-f06a860c5169"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / Loss: 1.6658228635787964\n",
            "Epoch: 1 / Loss: 1.143695592880249\n",
            "Epoch: 2 / Loss: 1.0097492933273315\n",
            "Epoch: 3 / Loss: 0.9588073492050171\n",
            "Epoch: 4 / Loss: 0.9248340129852295\n",
            "Epoch: 5 / Loss: 0.8981516361236572\n",
            "Epoch: 6 / Loss: 0.8740020990371704\n",
            "Epoch: 7 / Loss: 0.8506496548652649\n",
            "Epoch: 8 / Loss: 0.8275310397148132\n",
            "Epoch: 9 / Loss: 0.8046189546585083\n",
            "Epoch: 10 / Loss: 0.7818830609321594\n",
            "Epoch: 11 / Loss: 0.7599788308143616\n",
            "Epoch: 12 / Loss: 0.7389342188835144\n",
            "Epoch: 13 / Loss: 0.7189435362815857\n",
            "Epoch: 14 / Loss: 0.7001339197158813\n",
            "Epoch: 15 / Loss: 0.6825770139694214\n",
            "Epoch: 16 / Loss: 0.6662886142730713\n",
            "Epoch: 17 / Loss: 0.6512442231178284\n",
            "Epoch: 18 / Loss: 0.6373910307884216\n",
            "Epoch: 19 / Loss: 0.6246609091758728\n",
            "Epoch: 20 / Loss: 0.612968385219574\n",
            "Epoch: 21 / Loss: 0.6022309064865112\n",
            "Epoch: 22 / Loss: 0.5923649072647095\n",
            "Epoch: 23 / Loss: 0.5832911133766174\n",
            "Epoch: 24 / Loss: 0.574936032295227\n",
            "Epoch: 25 / Loss: 0.5672246813774109\n",
            "Epoch: 26 / Loss: 0.5600841045379639\n",
            "Epoch: 27 / Loss: 0.5534486174583435\n",
            "Epoch: 28 / Loss: 0.5472570061683655\n",
            "Epoch: 29 / Loss: 0.5414677262306213\n",
            "Epoch: 30 / Loss: 0.5360090136528015\n",
            "Epoch: 31 / Loss: 0.5308253765106201\n",
            "Epoch: 32 / Loss: 0.5258817672729492\n",
            "Epoch: 33 / Loss: 0.5211158394813538\n",
            "Epoch: 34 / Loss: 0.5164957046508789\n",
            "Epoch: 35 / Loss: 0.5119857788085938\n",
            "Epoch: 36 / Loss: 0.5075134634971619\n",
            "Epoch: 37 / Loss: 0.503043532371521\n",
            "Epoch: 38 / Loss: 0.498611181974411\n",
            "Epoch: 39 / Loss: 0.4941887855529785\n",
            "Epoch: 40 / Loss: 0.4897918105125427\n",
            "Epoch: 41 / Loss: 0.48536762595176697\n",
            "Epoch: 42 / Loss: 0.4809151589870453\n",
            "Epoch: 43 / Loss: 0.4765031039714813\n",
            "Epoch: 44 / Loss: 0.47218674421310425\n",
            "Epoch: 45 / Loss: 0.4679289162158966\n",
            "Epoch: 46 / Loss: 0.4636256992816925\n",
            "Epoch: 47 / Loss: 0.4592912197113037\n",
            "Epoch: 48 / Loss: 0.45502862334251404\n",
            "Epoch: 49 / Loss: 0.450741171836853\n",
            "Epoch: 50 / Loss: 0.4464603662490845\n",
            "Epoch: 51 / Loss: 0.44228890538215637\n",
            "Epoch: 52 / Loss: 0.4381839632987976\n",
            "Epoch: 53 / Loss: 0.43413060903549194\n",
            "Epoch: 54 / Loss: 0.4301076829433441\n",
            "Epoch: 55 / Loss: 0.42612016201019287\n",
            "Epoch: 56 / Loss: 0.42214661836624146\n",
            "Epoch: 57 / Loss: 0.41819971799850464\n",
            "Epoch: 58 / Loss: 0.41428640484809875\n",
            "Epoch: 59 / Loss: 0.4103873074054718\n",
            "Epoch: 60 / Loss: 0.4064994752407074\n",
            "Epoch: 61 / Loss: 0.4026346802711487\n",
            "Epoch: 62 / Loss: 0.3988129794597626\n",
            "Epoch: 63 / Loss: 0.3950100541114807\n",
            "Epoch: 64 / Loss: 0.391251802444458\n",
            "Epoch: 65 / Loss: 0.3875143229961395\n",
            "Epoch: 66 / Loss: 0.3837946653366089\n",
            "Epoch: 67 / Loss: 0.3800921142101288\n",
            "Epoch: 68 / Loss: 0.3764066696166992\n",
            "Epoch: 69 / Loss: 0.37273871898651123\n",
            "Epoch: 70 / Loss: 0.36909735202789307\n",
            "Epoch: 71 / Loss: 0.365491658449173\n",
            "Epoch: 72 / Loss: 0.3619074821472168\n",
            "Epoch: 73 / Loss: 0.35834431648254395\n",
            "Epoch: 74 / Loss: 0.3548024296760559\n",
            "Epoch: 75 / Loss: 0.35128217935562134\n",
            "Epoch: 76 / Loss: 0.34778428077697754\n",
            "Epoch: 77 / Loss: 0.34430938959121704\n",
            "Epoch: 78 / Loss: 0.3408582806587219\n",
            "Epoch: 79 / Loss: 0.3374318480491638\n",
            "Epoch: 80 / Loss: 0.3340330719947815\n",
            "Epoch: 81 / Loss: 0.33067625761032104\n",
            "Epoch: 82 / Loss: 0.3273617923259735\n",
            "Epoch: 83 / Loss: 0.32409659028053284\n",
            "Epoch: 84 / Loss: 0.3209170401096344\n",
            "Epoch: 85 / Loss: 0.317794531583786\n",
            "Epoch: 86 / Loss: 0.3148788809776306\n",
            "Epoch: 87 / Loss: 0.31216368079185486\n",
            "Epoch: 88 / Loss: 0.3099955916404724\n",
            "Epoch: 89 / Loss: 0.3087550103664398\n",
            "Epoch: 90 / Loss: 0.30971604585647583\n",
            "Epoch: 91 / Loss: 0.3151727020740509\n",
            "Epoch: 92 / Loss: 0.32876071333885193\n",
            "Epoch: 93 / Loss: 0.3647363781929016\n",
            "Epoch: 94 / Loss: 0.41880595684051514\n",
            "Epoch: 95 / Loss: 0.5232053399085999\n",
            "Epoch: 96 / Loss: 0.4987207055091858\n",
            "Epoch: 97 / Loss: 0.5790467858314514\n",
            "Epoch: 98 / Loss: 0.43753188848495483\n",
            "Epoch: 99 / Loss: 0.4834597408771515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(100)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9Wk2_ahIVJfz",
        "outputId": "e353b15e-925b-4079-be3d-7e1df6bce806"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / Loss: 1.5614030361175537\n",
            "Epoch: 1 / Loss: 5.540131092071533\n",
            "Epoch: 2 / Loss: 5.202388763427734\n",
            "Epoch: 3 / Loss: 4.379126071929932\n",
            "Epoch: 4 / Loss: 2.548936128616333\n",
            "Epoch: 5 / Loss: 0.9877969622612\n",
            "Epoch: 6 / Loss: 0.5903506875038147\n",
            "Epoch: 7 / Loss: 0.47673487663269043\n",
            "Epoch: 8 / Loss: 0.4511124789714813\n",
            "Epoch: 9 / Loss: 0.43401169776916504\n",
            "Epoch: 10 / Loss: 0.42020195722579956\n",
            "Epoch: 11 / Loss: 0.40810292959213257\n",
            "Epoch: 12 / Loss: 0.3971702456474304\n",
            "Epoch: 13 / Loss: 0.38705065846443176\n",
            "Epoch: 14 / Loss: 0.37757623195648193\n",
            "Epoch: 15 / Loss: 0.36865776777267456\n",
            "Epoch: 16 / Loss: 0.36026445031166077\n",
            "Epoch: 17 / Loss: 0.35230720043182373\n",
            "Epoch: 18 / Loss: 0.34472841024398804\n",
            "Epoch: 19 / Loss: 0.33748409152030945\n",
            "Epoch: 20 / Loss: 0.33053839206695557\n",
            "Epoch: 21 / Loss: 0.323862224817276\n",
            "Epoch: 22 / Loss: 0.31743577122688293\n",
            "Epoch: 23 / Loss: 0.31125593185424805\n",
            "Epoch: 24 / Loss: 0.30532345175743103\n",
            "Epoch: 25 / Loss: 0.299608051776886\n",
            "Epoch: 26 / Loss: 0.29412150382995605\n",
            "Epoch: 27 / Loss: 0.2889035940170288\n",
            "Epoch: 28 / Loss: 0.28403154015541077\n",
            "Epoch: 29 / Loss: 0.2795265316963196\n",
            "Epoch: 30 / Loss: 0.2756483852863312\n",
            "Epoch: 31 / Loss: 0.27275151014328003\n",
            "Epoch: 32 / Loss: 0.2721589505672455\n",
            "Epoch: 33 / Loss: 0.27499011158943176\n",
            "Epoch: 34 / Loss: 0.28791457414627075\n",
            "Epoch: 35 / Loss: 0.3108524680137634\n",
            "Epoch: 36 / Loss: 0.3723542392253876\n",
            "Epoch: 37 / Loss: 0.4179106652736664\n",
            "Epoch: 38 / Loss: 0.532954216003418\n",
            "Epoch: 39 / Loss: 0.4629465341567993\n",
            "Epoch: 40 / Loss: 0.5199673771858215\n",
            "Epoch: 41 / Loss: 0.40232744812965393\n",
            "Epoch: 42 / Loss: 0.42164698243141174\n",
            "Epoch: 43 / Loss: 0.35168570280075073\n",
            "Epoch: 44 / Loss: 0.36165186762809753\n",
            "Epoch: 45 / Loss: 0.3200903832912445\n",
            "Epoch: 46 / Loss: 0.3271327614784241\n",
            "Epoch: 47 / Loss: 0.3017537295818329\n",
            "Epoch: 48 / Loss: 0.30996954441070557\n",
            "Epoch: 49 / Loss: 0.2914770543575287\n",
            "Epoch: 50 / Loss: 0.30144476890563965\n",
            "Epoch: 51 / Loss: 0.28609979152679443\n",
            "Epoch: 52 / Loss: 0.2984563708305359\n",
            "Epoch: 53 / Loss: 0.28454267978668213\n",
            "Epoch: 54 / Loss: 0.29970577359199524\n",
            "Epoch: 55 / Loss: 0.2854786813259125\n",
            "Epoch: 56 / Loss: 0.3035092055797577\n",
            "Epoch: 57 / Loss: 0.2875593900680542\n",
            "Epoch: 58 / Loss: 0.3077700436115265\n",
            "Epoch: 59 / Loss: 0.28913241624832153\n",
            "Epoch: 60 / Loss: 0.31044498085975647\n",
            "Epoch: 61 / Loss: 0.2890441119670868\n",
            "Epoch: 62 / Loss: 0.310621052980423\n",
            "Epoch: 63 / Loss: 0.28676214814186096\n",
            "Epoch: 64 / Loss: 0.3079432547092438\n",
            "Epoch: 65 / Loss: 0.2830764651298523\n",
            "Epoch: 66 / Loss: 0.30357521772384644\n",
            "Epoch: 67 / Loss: 0.27873995900154114\n",
            "Epoch: 68 / Loss: 0.2985523045063019\n",
            "Epoch: 69 / Loss: 0.27415722608566284\n",
            "Epoch: 70 / Loss: 0.2937016189098358\n",
            "Epoch: 71 / Loss: 0.2700388431549072\n",
            "Epoch: 72 / Loss: 0.2894710302352905\n",
            "Epoch: 73 / Loss: 0.26628491282463074\n",
            "Epoch: 74 / Loss: 0.285748690366745\n",
            "Epoch: 75 / Loss: 0.2631303369998932\n",
            "Epoch: 76 / Loss: 0.28248971700668335\n",
            "Epoch: 77 / Loss: 0.26014143228530884\n",
            "Epoch: 78 / Loss: 0.2800042927265167\n",
            "Epoch: 79 / Loss: 0.25800275802612305\n",
            "Epoch: 80 / Loss: 0.2780638039112091\n",
            "Epoch: 81 / Loss: 0.2559680640697479\n",
            "Epoch: 82 / Loss: 0.276523232460022\n",
            "Epoch: 83 / Loss: 0.25431501865386963\n",
            "Epoch: 84 / Loss: 0.2752780020236969\n",
            "Epoch: 85 / Loss: 0.2525838613510132\n",
            "Epoch: 86 / Loss: 0.2736678421497345\n",
            "Epoch: 87 / Loss: 0.2509644329547882\n",
            "Epoch: 88 / Loss: 0.2725467085838318\n",
            "Epoch: 89 / Loss: 0.24910657107830048\n",
            "Epoch: 90 / Loss: 0.2707693874835968\n",
            "Epoch: 91 / Loss: 0.24729448556900024\n",
            "Epoch: 92 / Loss: 0.2686220407485962\n",
            "Epoch: 93 / Loss: 0.24478670954704285\n",
            "Epoch: 94 / Loss: 0.26619890332221985\n",
            "Epoch: 95 / Loss: 0.24243728816509247\n",
            "Epoch: 96 / Loss: 0.26359236240386963\n",
            "Epoch: 97 / Loss: 0.24006007611751556\n",
            "Epoch: 98 / Loss: 0.2611858546733856\n",
            "Epoch: 99 / Loss: 0.23772166669368744\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = MLP(1000)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=0.1)\n",
        "train(model, optimizer, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mE7-CEbpV3pv",
        "outputId": "2d744f99-29d9-45d1-9860-7e29adbe53b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 / Loss: 1.1801069974899292\n",
            "Epoch: 1 / Loss: 41.60044860839844\n",
            "Epoch: 2 / Loss: 55.048072814941406\n",
            "Epoch: 3 / Loss: 99.12351989746094\n",
            "Epoch: 4 / Loss: 6.811916828155518\n",
            "Epoch: 5 / Loss: 3.1195802688598633\n",
            "Epoch: 6 / Loss: 6.450865268707275\n",
            "Epoch: 7 / Loss: 0.41194775700569153\n",
            "Epoch: 8 / Loss: 2.776925563812256\n",
            "Epoch: 9 / Loss: 2.0952019691467285\n",
            "Epoch: 10 / Loss: 2.853532314300537\n",
            "Epoch: 11 / Loss: 0.4692821204662323\n",
            "Epoch: 12 / Loss: 0.8774638772010803\n",
            "Epoch: 13 / Loss: 0.6854815483093262\n",
            "Epoch: 14 / Loss: 0.8611934185028076\n",
            "Epoch: 15 / Loss: 0.3497733473777771\n",
            "Epoch: 16 / Loss: 0.25719568133354187\n",
            "Epoch: 17 / Loss: 0.09895920753479004\n",
            "Epoch: 18 / Loss: 0.08368251472711563\n",
            "Epoch: 19 / Loss: 0.07809238135814667\n",
            "Epoch: 20 / Loss: 0.07708665728569031\n",
            "Epoch: 21 / Loss: 0.07659450173377991\n",
            "Epoch: 22 / Loss: 0.07622800767421722\n",
            "Epoch: 23 / Loss: 0.07589323818683624\n",
            "Epoch: 24 / Loss: 0.07557051628828049\n",
            "Epoch: 25 / Loss: 0.07525938749313354\n",
            "Epoch: 26 / Loss: 0.07495815306901932\n",
            "Epoch: 27 / Loss: 0.07466532289981842\n",
            "Epoch: 28 / Loss: 0.07438038289546967\n",
            "Epoch: 29 / Loss: 0.07410304248332977\n",
            "Epoch: 30 / Loss: 0.07383240759372711\n",
            "Epoch: 31 / Loss: 0.0735706239938736\n",
            "Epoch: 32 / Loss: 0.0733170285820961\n",
            "Epoch: 33 / Loss: 0.07306975871324539\n",
            "Epoch: 34 / Loss: 0.07282836735248566\n",
            "Epoch: 35 / Loss: 0.07259254157543182\n",
            "Epoch: 36 / Loss: 0.0723620131611824\n",
            "Epoch: 37 / Loss: 0.07213791459798813\n",
            "Epoch: 38 / Loss: 0.07192200422286987\n",
            "Epoch: 39 / Loss: 0.07171289622783661\n",
            "Epoch: 40 / Loss: 0.07150807976722717\n",
            "Epoch: 41 / Loss: 0.0713040754199028\n",
            "Epoch: 42 / Loss: 0.07110537588596344\n",
            "Epoch: 43 / Loss: 0.0709121897816658\n",
            "Epoch: 44 / Loss: 0.07072402536869049\n",
            "Epoch: 45 / Loss: 0.07054045051336288\n",
            "Epoch: 46 / Loss: 0.07036229968070984\n",
            "Epoch: 47 / Loss: 0.07018742710351944\n",
            "Epoch: 48 / Loss: 0.0700146034359932\n",
            "Epoch: 49 / Loss: 0.06984449923038483\n",
            "Epoch: 50 / Loss: 0.06967704743146896\n",
            "Epoch: 51 / Loss: 0.06950995326042175\n",
            "Epoch: 52 / Loss: 0.06934334337711334\n",
            "Epoch: 53 / Loss: 0.069181889295578\n",
            "Epoch: 54 / Loss: 0.06902344524860382\n",
            "Epoch: 55 / Loss: 0.06886735558509827\n",
            "Epoch: 56 / Loss: 0.06871429085731506\n",
            "Epoch: 57 / Loss: 0.06856516748666763\n",
            "Epoch: 58 / Loss: 0.06842058151960373\n",
            "Epoch: 59 / Loss: 0.06827939301729202\n",
            "Epoch: 60 / Loss: 0.06814149767160416\n",
            "Epoch: 61 / Loss: 0.06800778210163116\n",
            "Epoch: 62 / Loss: 0.0678764060139656\n",
            "Epoch: 63 / Loss: 0.06774704903364182\n",
            "Epoch: 64 / Loss: 0.0676199346780777\n",
            "Epoch: 65 / Loss: 0.06749483197927475\n",
            "Epoch: 66 / Loss: 0.06737179309129715\n",
            "Epoch: 67 / Loss: 0.0672505795955658\n",
            "Epoch: 68 / Loss: 0.06713048368692398\n",
            "Epoch: 69 / Loss: 0.06700990349054337\n",
            "Epoch: 70 / Loss: 0.06689129769802094\n",
            "Epoch: 71 / Loss: 0.06677478551864624\n",
            "Epoch: 72 / Loss: 0.06666006147861481\n",
            "Epoch: 73 / Loss: 0.06654684990644455\n",
            "Epoch: 74 / Loss: 0.06643544137477875\n",
            "Epoch: 75 / Loss: 0.06632551550865173\n",
            "Epoch: 76 / Loss: 0.0662173181772232\n",
            "Epoch: 77 / Loss: 0.06611042469739914\n",
            "Epoch: 78 / Loss: 0.06600506603717804\n",
            "Epoch: 79 / Loss: 0.06590118259191513\n",
            "Epoch: 80 / Loss: 0.06579804420471191\n",
            "Epoch: 81 / Loss: 0.06569642573595047\n",
            "Epoch: 82 / Loss: 0.06559590250253677\n",
            "Epoch: 83 / Loss: 0.06549651175737381\n",
            "Epoch: 84 / Loss: 0.06539728492498398\n",
            "Epoch: 85 / Loss: 0.06529845297336578\n",
            "Epoch: 86 / Loss: 0.06520093977451324\n",
            "Epoch: 87 / Loss: 0.06510436534881592\n",
            "Epoch: 88 / Loss: 0.06500895321369171\n",
            "Epoch: 89 / Loss: 0.06491531431674957\n",
            "Epoch: 90 / Loss: 0.06482332199811935\n",
            "Epoch: 91 / Loss: 0.06473221629858017\n",
            "Epoch: 92 / Loss: 0.0646418109536171\n",
            "Epoch: 93 / Loss: 0.06455264240503311\n",
            "Epoch: 94 / Loss: 0.06446428596973419\n",
            "Epoch: 95 / Loss: 0.06437685340642929\n",
            "Epoch: 96 / Loss: 0.06429032236337662\n",
            "Epoch: 97 / Loss: 0.06420429050922394\n",
            "Epoch: 98 / Loss: 0.06411910057067871\n",
            "Epoch: 99 / Loss: 0.0640350878238678\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "68HPPQ3rWIi0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}